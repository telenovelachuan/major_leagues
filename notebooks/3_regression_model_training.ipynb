{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and validating linear regression model\n",
      "cross val scores for score1:[-1.68636132e+32 -3.25890564e+30 -6.47123521e+33]\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/training.csv\")\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "col_to_remove = [\"score1\", \"score2\"]\n",
    "X_train = train_set.drop(columns=col_to_remove, axis=1)\n",
    "X_test = test_set.drop(columns=col_to_remove, axis=1)\n",
    "y_train1, y_train2 = train_set[\"score1\"], train_set[\"score2\"]\n",
    "y_test1, y_test2 = test_set[\"score1\"], test_set[\"score2\"]\n",
    "\n",
    "print \"Fitting and validating linear regression model\"\n",
    "linear_model = load(\"../models/linear_regression_score1.joblib\")\n",
    "scores1 = cross_val_score(linear_model, X_train, y_train1, cv=3, scoring='r2')\n",
    "print \"cross val scores for score1:{}\".format(scores1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and validating random forest\n",
      "cross val scores for score1:[0.26469125 0.27185484 0.24673161]\n"
     ]
    }
   ],
   "source": [
    "print \"Fitting and validating random forest\"\n",
    "rf_model = load(\"../models/random_forest_score1.joblib\")\n",
    "scores1 = cross_val_score(rf_model, X_train, y_train1, cv=3, scoring='r2')\n",
    "print \"cross val scores for score1:{}\".format(scores1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained neural network model\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               160700    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "score1_output (Dense)        (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 191,101\n",
      "Trainable params: 191,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "model loaded: None\n"
     ]
    }
   ],
   "source": [
    "print \"Loading the trained neural network model\"\n",
    "from keras.models import load_model, model_from_json\n",
    "score = 'score1'\n",
    "with open('../models/NN_{}.json'.format(score)) as f:\n",
    "    model = model_from_json(f.read())\n",
    "    model.load_weights('../models/NN_{}.h5'.format(score))\n",
    "f.close()\n",
    "print \"model loaded: {}\".format(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and shaping real football game data for predicting.\n",
      "cases to predict:\n",
      "\n",
      "[2019, 10, 18, 'Eintracht Frankfurt', 'Bayer Leverkusen']\n",
      "[2019, 10, 19, 'Everton', 'West Ham United']\n",
      "[2019, 10, 27, 'Liverpool', 'Tottenham Hotspur']\n",
      "[2019, 10, 26, 'Bayern Munich', '1. FC Union Berlin']\n",
      "[2019, 10, 20, 'Parma', 'Genoa']\n"
     ]
    }
   ],
   "source": [
    "print \"Generating and shaping real football game data for predicting.\"\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "processed = pd.read_csv(\"../data/processed/processed.csv\")\n",
    "original_df = processed\n",
    "predict_case_indexes = [37, 68, 584, 432, 247]\n",
    "rows_display = [original_df[original_df.index.isin([idx + 25831])] for idx in predict_case_indexes]\n",
    "def prepare_data_for_predict_set():\n",
    "    \n",
    "    processed.drop(columns=['date', 'score1', 'score2'], axis=1, inplace=True)\n",
    "    columns_to_dummy = ['league', 'team1', 'team2']\n",
    "    df = pd.get_dummies(processed, columns=columns_to_dummy)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    df_columns = df.columns.to_list()\n",
    "\n",
    "    df[df_columns] = num_pipeline.fit_transform(df[df_columns])\n",
    "\n",
    "    \n",
    "    \n",
    "    rows = [df[df.index.isin([idx])] for idx in predict_case_indexes]\n",
    "    games = [[row.iloc[0]['year'], row.iloc[0]['month'], row.iloc[0]['day'], row.iloc[0]['team1'], row.iloc[0]['team2']] for row in rows_display]\n",
    "    print \"cases to predict:\\n\"\n",
    "    for g in games:\n",
    "        print g\n",
    "    rows_ndarray = [row.to_numpy() for row in rows]\n",
    "    return rows_ndarray\n",
    "\n",
    "rows = prepare_data_for_predict_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained neural network model, and using it to predict real live football match scores.\n",
      "predicting on Eintracht Frankfurt vs Bayer Leverkusen\n",
      "prediction for score1 :[[0.77133083]]\n",
      "prediction for score2 :[[1.7512617]]\n",
      "predicting on Everton vs West Ham United\n",
      "prediction for score1 :[[1.0281343]]\n",
      "prediction for score2 :[[0.97937214]]\n",
      "predicting on Liverpool vs Tottenham Hotspur\n",
      "prediction for score1 :[[3.5695443]]\n",
      "prediction for score2 :[[0.9038845]]\n",
      "predicting on Bayern Munich vs 1. FC Union Berlin\n",
      "prediction for score1 :[[2.9759655]]\n",
      "prediction for score2 :[[0.9898988]]\n",
      "predicting on Parma vs Genoa\n",
      "prediction for score1 :[[3.1643186]]\n",
      "prediction for score2 :[[0.9877361]]\n"
     ]
    }
   ],
   "source": [
    "print \"Loading the trained neural network model, and using it to predict real live football match scores.\"\n",
    "from keras.models import load_model, model_from_json\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def load_model(score_name):\n",
    "    with open('../models/NN_{}.json'.format(score_name)) as f:\n",
    "        model = model_from_json(f.read())\n",
    "        model.load_weights('../models/NN_{}.h5'.format(score_name))\n",
    "    f.close()\n",
    "    return model\n",
    "\n",
    "model1 = load_model('score1')\n",
    "model2 = load_model('score2')\n",
    "\n",
    "def use_model_to_predict(score, row_value_array):\n",
    "    model = model1 if score == 'score1' else model2\n",
    "    prediction = model.predict(row_value_array)\n",
    "    print \"prediction for {} :{}\".format(score, prediction)\n",
    "\n",
    "\n",
    "for idx, row in enumerate(rows):\n",
    "    row_display = rows_display[idx]\n",
    "    print \"predicting on {} vs {}\".format(row_display.iloc[0]['team1'], row_display.iloc[0]['team2'])\n",
    "    use_model_to_predict('score1', row)\n",
    "    use_model_to_predict('score2', row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
